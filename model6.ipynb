{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ead8eb4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset shape: (3448, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>interview_question</th>\n",
              "      <th>interview_answer</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>inaudible</th>\n",
              "      <th>multiple_questions</th>\n",
              "      <th>affirmative_questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How would you respond to the accusation that t...</td>\n",
              "      <td>Q. Of the Biden administration. And accused th...</td>\n",
              "      <td>Well, look, first of all, theI am sincere abou...</td>\n",
              "      <td>Explicit</td>\n",
              "      <td>https://www.presidency.ucsb.edu/documents/the-...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Do you think President Xi is being sincere abo...</td>\n",
              "      <td>Q. Of the Biden administration. And accused th...</td>\n",
              "      <td>Well, look, first of all, theI am sincere abou...</td>\n",
              "      <td>General</td>\n",
              "      <td>https://www.presidency.ucsb.edu/documents/the-...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Do you believe the country's slowdown and gro...</td>\n",
              "      <td>Q. No worries. Do you believe the country's sl...</td>\n",
              "      <td>Look, I think China has a difficult economic p...</td>\n",
              "      <td>Partial/half-answer</td>\n",
              "      <td>https://www.presidency.ucsb.edu/documents/the-...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are you worried about the meeting between Pre...</td>\n",
              "      <td>Q. No worries. Do you believe the country's sl...</td>\n",
              "      <td>Look, I think China has a difficult economic p...</td>\n",
              "      <td>Dodging</td>\n",
              "      <td>https://www.presidency.ucsb.edu/documents/the-...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Is the President's engagement with Asian coun...</td>\n",
              "      <td>Q. I can imagine. It is evening, I'd like to r...</td>\n",
              "      <td>Well, I hope I get to see Mr. Xi sooner than l...</td>\n",
              "      <td>Explicit</td>\n",
              "      <td>https://www.presidency.ucsb.edu/documents/the-...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  How would you respond to the accusation that t...   \n",
              "1  Do you think President Xi is being sincere abo...   \n",
              "2   Do you believe the country's slowdown and gro...   \n",
              "3   Are you worried about the meeting between Pre...   \n",
              "4   Is the President's engagement with Asian coun...   \n",
              "\n",
              "                                  interview_question  \\\n",
              "0  Q. Of the Biden administration. And accused th...   \n",
              "1  Q. Of the Biden administration. And accused th...   \n",
              "2  Q. No worries. Do you believe the country's sl...   \n",
              "3  Q. No worries. Do you believe the country's sl...   \n",
              "4  Q. I can imagine. It is evening, I'd like to r...   \n",
              "\n",
              "                                    interview_answer                label  \\\n",
              "0  Well, look, first of all, theI am sincere abou...             Explicit   \n",
              "1  Well, look, first of all, theI am sincere abou...              General   \n",
              "2  Look, I think China has a difficult economic p...  Partial/half-answer   \n",
              "3  Look, I think China has a difficult economic p...              Dodging   \n",
              "4  Well, I hope I get to see Mr. Xi sooner than l...             Explicit   \n",
              "\n",
              "                                                 url  inaudible  \\\n",
              "0  https://www.presidency.ucsb.edu/documents/the-...      False   \n",
              "1  https://www.presidency.ucsb.edu/documents/the-...      False   \n",
              "2  https://www.presidency.ucsb.edu/documents/the-...      False   \n",
              "3  https://www.presidency.ucsb.edu/documents/the-...      False   \n",
              "4  https://www.presidency.ucsb.edu/documents/the-...      False   \n",
              "\n",
              "   multiple_questions  affirmative_questions  \n",
              "0               False                  False  \n",
              "1               False                  False  \n",
              "2               False                  False  \n",
              "3               False                  False  \n",
              "4               False                  False  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "arrow_path = \"dataset/train/train/data-00000-of-00001.arrow\"\n",
        "train_ds = Dataset.from_file(arrow_path)\n",
        "\n",
        "train_df = train_ds.to_pandas()\n",
        "\n",
        "print(f\"Train dataset shape: {train_df.shape}\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ba39c6c4",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "Loading spaCy model...\n",
            "Loading Sentence-BERT model...\n",
            "Loading VADER sentiment analyzer...\n",
            "All models loaded!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "print(\"Loading spaCy model...\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "print(\"Loading Sentence-BERT model...\")\n",
        "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Loading VADER sentiment analyzer...\")\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "print(\"All models loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bca08e28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "LEXICON STATUS\n",
            "==================================================\n",
            "  ✓ AFINN\n",
            "  ✗ NRC EmoLex\n",
            "  ✗ Brysbaert Concreteness\n",
            "  ✗ MPQA Subjectivity\n",
            "  ✓ Hedge Words\n",
            "==================================================\n",
            "\n",
            "Hedge words loaded: 162\n",
            "NRC emotions available: False\n",
            "Concreteness ratings: 0\n",
            "MPQA subjective words: 0\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# LOAD PROFESSIONAL NLP LEXICONS\n",
        "# ============================================\n",
        "# Using established academic lexicons:\n",
        "# - AFINN: Sentiment scores (Nielsen, 2011)\n",
        "# - NRC EmoLex: Emotion associations (Mohammad & Turney, 2013)\n",
        "# - Brysbaert: Concreteness ratings (Brysbaert et al., 2014)\n",
        "# - MPQA: Subjectivity classification (Wilson et al., 2005)\n",
        "\n",
        "from lexicon_loader import lexicons\n",
        "\n",
        "# Print status of loaded lexicons\n",
        "lexicons.print_status()\n",
        "\n",
        "# Export lexicon variables for feature functions\n",
        "HEDGE_WORDS = lexicons.hedge_words\n",
        "MODAL_VERBS = lexicons.modal_verbs\n",
        "NEGATION_WORDS = lexicons.negation_words\n",
        "FILLER_WORDS_SET = lexicons.filler_words\n",
        "FILLER_PHRASES = lexicons.filler_phrases\n",
        "VAGUE_WORDS_SET = lexicons.vague_words\n",
        "VAGUE_PHRASES = lexicons.vague_phrases\n",
        "PIVOT_PHRASES = lexicons.pivot_phrases\n",
        "THANKS_STARTERS = lexicons.thanks_starters\n",
        "\n",
        "# Professional lexicons (for enhanced features)\n",
        "NRC_EMOTIONS = lexicons.nrc_emotions\n",
        "CONCRETENESS_RATINGS = lexicons.concreteness\n",
        "MPQA_STRONG = lexicons.mpqa_strong_subjective\n",
        "MPQA_WEAK = lexicons.mpqa_weak_subjective\n",
        "\n",
        "print(f\"\\nHedge words loaded: {len(HEDGE_WORDS)}\")\n",
        "print(f\"NRC emotions available: {bool(NRC_EMOTIONS.get('anger'))}\")\n",
        "print(f\"Concreteness ratings: {len(CONCRETENESS_RATINGS)}\")\n",
        "print(f\"MPQA subjective words: {len(MPQA_STRONG) + len(MPQA_WEAK)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c6f147bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_semantic_features(questions, answers):\n",
        "    print(\"Encoding questions...\")\n",
        "    q_embeddings = sbert_model.encode(questions.tolist(), show_progress_bar=True)\n",
        "    print(\"Encoding answers...\")\n",
        "    a_embeddings = sbert_model.encode(answers.tolist(), show_progress_bar=True)\n",
        "    qa_similarity = np.array([\n",
        "        np.dot(q, a) / (np.linalg.norm(q) * np.linalg.norm(a) + 1e-8)\n",
        "        for q, a in zip(q_embeddings, a_embeddings)\n",
        "    ])\n",
        "    topic_shift_score = 1 - qa_similarity\n",
        "    return qa_similarity, topic_shift_score\n",
        "\n",
        "def compute_keyword_overlap(question, answer):\n",
        "    q_doc = nlp(question.lower())\n",
        "    a_doc = nlp(answer.lower())\n",
        "    q_words = {token.lemma_ for token in q_doc if not token.is_stop and token.is_alpha}\n",
        "    a_words = {token.lemma_ for token in a_doc if not token.is_stop and token.is_alpha}\n",
        "    if len(q_words) == 0:\n",
        "        return 0.0\n",
        "    overlap = len(q_words & a_words)\n",
        "    return overlap / len(q_words)\n",
        "\n",
        "def compute_entity_overlap(question, answer):\n",
        "    q_doc = nlp(question)\n",
        "    a_doc = nlp(answer)\n",
        "    q_entities = {ent.text.lower() for ent in q_doc.ents}\n",
        "    a_entities = {ent.text.lower() for ent in a_doc.ents}\n",
        "    return len(q_entities & a_entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb9798be",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_structure_features(question, answer):\n",
        "    a_doc = nlp(answer)\n",
        "    answer_length_tokens = len([t for t in a_doc if not t.is_space])\n",
        "    answer_length_chars = len(answer)\n",
        "    q_len = len(question)\n",
        "    answer_to_question_len_ratio = answer_length_chars / q_len if q_len > 0 else 0\n",
        "    sentences = list(a_doc.sents)\n",
        "    num_sentences = len(sentences)\n",
        "    return {\n",
        "        'answer_length_tokens': answer_length_tokens,\n",
        "        'answer_length_chars': answer_length_chars,\n",
        "        'answer_to_question_len_ratio': answer_to_question_len_ratio,\n",
        "        'num_sentences': num_sentences\n",
        "    }\n",
        "\n",
        "def compute_first_sentence_similarity(questions, answers):\n",
        "    first_sentences = []\n",
        "    for answer in answers:\n",
        "        sents = sent_tokenize(answer)\n",
        "        first_sentences.append(sents[0] if sents else \"\")\n",
        "    print(\"Encoding first sentences...\")\n",
        "    q_emb = sbert_model.encode(questions.tolist(), show_progress_bar=True)\n",
        "    fs_emb = sbert_model.encode(first_sentences, show_progress_bar=True)\n",
        "    similarities = np.array([\n",
        "        np.dot(q, f) / (np.linalg.norm(q) * np.linalg.norm(f) + 1e-8)\n",
        "        for q, f in zip(q_emb, fs_emb)\n",
        "    ])\n",
        "    return similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "87a27602",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_hedging_features(answer):\n",
        "    answer_lower = answer.lower()\n",
        "    tokens = word_tokenize(answer_lower)\n",
        "    hedge_score = sum(1 for t in tokens if t in HEDGE_WORDS)\n",
        "    filler_score = sum(1 for t in tokens if t in FILLER_WORDS_SET)\n",
        "    for phrase in FILLER_PHRASES:\n",
        "        filler_score += answer_lower.count(phrase)\n",
        "    vague_word_count = sum(1 for t in tokens if t in VAGUE_WORDS_SET)\n",
        "    for phrase in VAGUE_PHRASES:\n",
        "        vague_word_count += answer_lower.count(phrase)\n",
        "    modal_verb_count = sum(1 for t in tokens if t in MODAL_VERBS)\n",
        "    return {\n",
        "        'hedge_score': hedge_score,\n",
        "        'filler_score': filler_score,\n",
        "        'vague_word_count': vague_word_count,\n",
        "        'modal_verb_count': modal_verb_count\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cee301e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_specificity_features(answer):\n",
        "    doc = nlp(answer)\n",
        "    num_numbers = sum(1 for token in doc if token.like_num or token.pos_ == 'NUM')\n",
        "    num_named_entities = len(doc.ents)\n",
        "    total_tokens = len([t for t in doc if t.is_alpha])\n",
        "    content_tokens = len([t for t in doc if t.is_alpha and not t.is_stop])\n",
        "    specificity_score = content_tokens / total_tokens if total_tokens > 0 else 0\n",
        "    return {\n",
        "        'num_numbers': num_numbers,\n",
        "        'num_named_entities': num_named_entities,\n",
        "        'specificity_score': specificity_score\n",
        "    }\n",
        "\n",
        "def compute_concreteness_score(answer):\n",
        "    \"\"\"Compute concreteness using Brysbaert ratings (1=abstract, 5=concrete).\"\"\"\n",
        "    if CONCRETENESS_RATINGS:\n",
        "        # Use professional Brysbaert concreteness ratings\n",
        "        tokens = word_tokenize(answer.lower())\n",
        "        scores = [CONCRETENESS_RATINGS.get(t, 0) for t in tokens if t.isalpha()]\n",
        "        valid_scores = [s for s in scores if s > 0]\n",
        "        return sum(valid_scores) / len(valid_scores) if valid_scores else 2.5  # 2.5 = neutral\n",
        "    else:\n",
        "        # Fallback: proxy based on NER and numbers\n",
        "        doc = nlp(answer)\n",
        "        concrete_indicators = len(doc.ents) + sum(1 for t in doc if t.like_num)\n",
        "        total = len([t for t in doc if t.is_alpha])\n",
        "        return (concrete_indicators / total * 5) if total > 0 else 2.5  # Scale to 1-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "724ca7a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_sentiment_features(answer):\n",
        "    \"\"\"Compute sentiment using VADER + AFINN (professional lexicon).\"\"\"\n",
        "    # VADER scores\n",
        "    vader_scores = sia.polarity_scores(answer)\n",
        "    \n",
        "    # AFINN score (normalized to -1 to 1 range)\n",
        "    afinn_score = lexicons.get_afinn_score(answer)\n",
        "    afinn_normalized = max(-1, min(1, afinn_score / 10))  # Normalize\n",
        "    \n",
        "    return {\n",
        "        'sentiment_compound': vader_scores['compound'],\n",
        "        'sentiment_positive': vader_scores['pos'],\n",
        "        'sentiment_negative': vader_scores['neg'],\n",
        "        'sentiment_neutral': vader_scores['neu'],\n",
        "        'afinn_score': afinn_normalized\n",
        "    }\n",
        "\n",
        "def compute_emotion_features(answer):\n",
        "    \"\"\"Compute emotion features using NRC EmoLex (professional lexicon).\"\"\"\n",
        "    tokens = word_tokenize(answer.lower())\n",
        "    token_count = len([t for t in tokens if t.isalpha()])\n",
        "    \n",
        "    if token_count == 0:\n",
        "        return {f'nrc_{e}': 0 for e in ['anger', 'fear', 'joy', 'sadness', 'trust', 'disgust']}\n",
        "    \n",
        "    # Count emotion words using NRC lexicon\n",
        "    emotion_counts = {}\n",
        "    for emotion, words in NRC_EMOTIONS.items():\n",
        "        count = sum(1 for t in tokens if t in words)\n",
        "        emotion_counts[f'nrc_{emotion}'] = count / token_count  # Normalized\n",
        "    \n",
        "    return emotion_counts\n",
        "\n",
        "def compute_emotion_confidence(answer):\n",
        "    \"\"\"Sentiment extremity as confidence proxy.\"\"\"\n",
        "    scores = sia.polarity_scores(answer)\n",
        "    return abs(scores['compound'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5636dad4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_syntactic_features(answer):\n",
        "    doc = nlp(answer)\n",
        "    total_tokens = len([t for t in doc if t.is_alpha])\n",
        "    if total_tokens == 0:\n",
        "        return {\n",
        "            'pos_ratio_verbs': 0,\n",
        "            'pos_ratio_nouns': 0,\n",
        "            'pos_ratio_pronouns': 0,\n",
        "            'num_clauses': 0\n",
        "        }\n",
        "    verbs = len([t for t in doc if t.pos_ == 'VERB'])\n",
        "    nouns = len([t for t in doc if t.pos_ == 'NOUN'])\n",
        "    pronouns = len([t for t in doc if t.pos_ == 'PRON'])\n",
        "    num_clauses = 1  \n",
        "    for token in doc:\n",
        "        if token.dep_ in ('ccomp', 'advcl', 'relcl', 'acl'):\n",
        "            num_clauses += 1\n",
        "    return {\n",
        "        'pos_ratio_verbs': verbs / total_tokens,\n",
        "        'pos_ratio_nouns': nouns / total_tokens,\n",
        "        'pos_ratio_pronouns': pronouns / total_tokens,\n",
        "        'num_clauses': num_clauses\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4850c26c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_evasion_features(answer):\n",
        "    answer_lower = answer.lower()\n",
        "    starts_with_thanks = int(any(answer_lower.strip().startswith(phrase) for phrase in THANKS_STARTERS))\n",
        "    pivot_score = sum(1 for phrase in PIVOT_PHRASES if phrase in answer_lower)\n",
        "    tokens = word_tokenize(answer_lower)\n",
        "    negation_count = sum(1 for t in tokens if t in NEGATION_WORDS or \"n't\" in t)\n",
        "    return {\n",
        "        'starts_with_thanks': starts_with_thanks,\n",
        "        'pivot_score': pivot_score,\n",
        "        'negation_count': negation_count\n",
        "    }\n",
        "\n",
        "def compute_deflection_score(question, answer):\n",
        "    q_doc = nlp(question)\n",
        "    a_doc = nlp(answer)\n",
        "    q_entities = {ent.text.lower() for ent in q_doc.ents}\n",
        "    a_entities = {ent.text.lower() for ent in a_doc.ents}\n",
        "    if len(a_entities) == 0:\n",
        "        return 0.0\n",
        "    new_entities = a_entities - q_entities\n",
        "    return len(new_entities) / len(a_entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "88987cd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_lexical_diversity(answer):\n",
        "    tokens = word_tokenize(answer.lower())\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "    if len(tokens) == 0:\n",
        "        return {'ttr': 0, 'entropy_score': 0}\n",
        "    unique_tokens = set(tokens)\n",
        "    ttr = len(unique_tokens) / len(tokens)\n",
        "    word_counts = Counter(tokens)\n",
        "    total = len(tokens)\n",
        "    probs = [count / total for count in word_counts.values()]\n",
        "    entropy_score = -sum(p * np.log2(p) for p in probs if p > 0)\n",
        "    return {\n",
        "        'ttr': ttr,\n",
        "        'entropy_score': entropy_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "15421ddf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_all_features(row):\n",
        "    \"\"\"Extract all linguistic features for a Q/A pair.\"\"\"\n",
        "    question = str(row['question'])\n",
        "    answer = str(row['interview_answer'])\n",
        "    features = {}\n",
        "    \n",
        "    # Structure features\n",
        "    features.update(compute_structure_features(question, answer))\n",
        "    \n",
        "    # Hedging features (using hedge lexicon)\n",
        "    features.update(compute_hedging_features(answer))\n",
        "    \n",
        "    # Specificity features\n",
        "    features.update(compute_specificity_features(answer))\n",
        "    features['concreteness_score'] = compute_concreteness_score(answer)\n",
        "    \n",
        "    # Sentiment features (VADER + AFINN)\n",
        "    features.update(compute_sentiment_features(answer))\n",
        "    features['emotion_confidence'] = compute_emotion_confidence(answer)\n",
        "    \n",
        "    # NRC Emotion features (if available)\n",
        "    if NRC_EMOTIONS.get('anger'):\n",
        "        features.update(compute_emotion_features(answer))\n",
        "    \n",
        "    # Syntactic features\n",
        "    features.update(compute_syntactic_features(answer))\n",
        "    \n",
        "    # Evasion pattern features\n",
        "    features.update(compute_evasion_features(answer))\n",
        "    features['deflection_score'] = compute_deflection_score(question, answer)\n",
        "    \n",
        "    # Lexical diversity\n",
        "    features.update(compute_lexical_diversity(answer))\n",
        "    \n",
        "    # Semantic overlap\n",
        "    features['keyword_overlap'] = compute_keyword_overlap(question, answer)\n",
        "    features['entity_overlap'] = compute_entity_overlap(question, answer)\n",
        "    \n",
        "    return pd.Series(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8ba905d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "EXTRACTING FEATURES\n",
            "==================================================\n",
            "\n",
            "[1/2] Computing semantic similarity features (batched)...\n",
            "Encoding questions...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b43c29f3fd84db5b9502f28516e2adc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding answers...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f97b02560904b3fb8cb38674d8a1ba2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1.5/2] Computing first sentence similarity (batched)...\n",
            "Encoding first sentences...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb21385df9fc488eb104e76282051dea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fada36602175453c9ea87a75044c823f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[2/2] Extracting row-wise features (this may take a few minutes)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3448/3448 [23:25<00:00,  2.45it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "FEATURE EXTRACTION COMPLETE!\n",
            "==================================================\n",
            "\n",
            "Final dataset shape: (3448, 41)\n",
            "New features added: 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"EXTRACTING FEATURES\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\n[1/2] Computing semantic similarity features (batched)...\")\n",
        "qa_similarity, topic_shift_score = compute_semantic_features(\n",
        "    train_df['question'], \n",
        "    train_df['interview_answer']\n",
        ")\n",
        "train_df['qa_similarity'] = qa_similarity\n",
        "train_df['topic_shift_score'] = topic_shift_score\n",
        "print(\"\\n[1.5/2] Computing first sentence similarity (batched)...\")\n",
        "train_df['first_sentence_similarity'] = compute_first_sentence_similarity(\n",
        "    train_df['question'],\n",
        "    train_df['interview_answer']\n",
        ")\n",
        "print(\"\\n[2/2] Extracting row-wise features (this may take a few minutes)...\")\n",
        "feature_df = train_df.progress_apply(extract_all_features, axis=1)\n",
        "train_df = pd.concat([train_df, feature_df], axis=1)\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"FEATURE EXTRACTION COMPLETE!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nFinal dataset shape: {train_df.shape}\")\n",
        "print(f\"New features added: {feature_df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3da759d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total feature columns: 32\n",
            "\n",
            "Feature columns:\n",
            "   1. qa_similarity\n",
            "   2. topic_shift_score\n",
            "   3. keyword_overlap\n",
            "   4. entity_overlap\n",
            "   5. first_sentence_similarity\n",
            "   6. answer_length_tokens\n",
            "   7. answer_length_chars\n",
            "   8. answer_to_question_len_ratio\n",
            "   9. num_sentences\n",
            "  10. hedge_score\n",
            "  11. filler_score\n",
            "  12. vague_word_count\n",
            "  13. modal_verb_count\n",
            "  14. num_numbers\n",
            "  15. num_named_entities\n",
            "  16. specificity_score\n",
            "  17. concreteness_score\n",
            "  18. sentiment_compound\n",
            "  19. sentiment_positive\n",
            "  20. sentiment_negative\n",
            "  21. sentiment_neutral\n",
            "  22. emotion_confidence\n",
            "  23. pos_ratio_verbs\n",
            "  24. pos_ratio_nouns\n",
            "  25. pos_ratio_pronouns\n",
            "  26. num_clauses\n",
            "  27. starts_with_thanks\n",
            "  28. pivot_score\n",
            "  29. negation_count\n",
            "  30. deflection_score\n",
            "  31. ttr\n",
            "  32. entropy_score\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qa_similarity</th>\n",
              "      <th>topic_shift_score</th>\n",
              "      <th>keyword_overlap</th>\n",
              "      <th>entity_overlap</th>\n",
              "      <th>first_sentence_similarity</th>\n",
              "      <th>answer_length_tokens</th>\n",
              "      <th>answer_length_chars</th>\n",
              "      <th>answer_to_question_len_ratio</th>\n",
              "      <th>num_sentences</th>\n",
              "      <th>hedge_score</th>\n",
              "      <th>...</th>\n",
              "      <th>pos_ratio_verbs</th>\n",
              "      <th>pos_ratio_nouns</th>\n",
              "      <th>pos_ratio_pronouns</th>\n",
              "      <th>num_clauses</th>\n",
              "      <th>starts_with_thanks</th>\n",
              "      <th>pivot_score</th>\n",
              "      <th>negation_count</th>\n",
              "      <th>deflection_score</th>\n",
              "      <th>ttr</th>\n",
              "      <th>entropy_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.523220</td>\n",
              "      <td>0.476780</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.125558</td>\n",
              "      <td>429.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>17.033898</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.131868</td>\n",
              "      <td>0.093407</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.465714</td>\n",
              "      <td>6.722073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.455990</td>\n",
              "      <td>0.544010</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.325216</td>\n",
              "      <td>429.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>17.631579</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.131868</td>\n",
              "      <td>0.093407</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.465714</td>\n",
              "      <td>6.722073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.679849</td>\n",
              "      <td>0.320151</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.745094</td>\n",
              "      <td>263.0</td>\n",
              "      <td>1246.0</td>\n",
              "      <td>7.506024</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.139640</td>\n",
              "      <td>0.099099</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.528302</td>\n",
              "      <td>6.303390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183232</td>\n",
              "      <td>0.816768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.214009</td>\n",
              "      <td>263.0</td>\n",
              "      <td>1246.0</td>\n",
              "      <td>8.964029</td>\n",
              "      <td>19.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.162162</td>\n",
              "      <td>0.139640</td>\n",
              "      <td>0.099099</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.528302</td>\n",
              "      <td>6.303390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.333183</td>\n",
              "      <td>0.666817</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123043</td>\n",
              "      <td>525.0</td>\n",
              "      <td>2502.0</td>\n",
              "      <td>30.144578</td>\n",
              "      <td>33.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139640</td>\n",
              "      <td>0.164414</td>\n",
              "      <td>0.101351</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.497685</td>\n",
              "      <td>7.100189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   qa_similarity  topic_shift_score  keyword_overlap  entity_overlap  \\\n",
              "0       0.523220           0.476780         0.555556             2.0   \n",
              "1       0.455990           0.544010         0.700000             2.0   \n",
              "2       0.679849           0.320151         0.357143             2.0   \n",
              "3       0.183232           0.816768         0.000000             0.0   \n",
              "4       0.333183           0.666817         0.375000             0.0   \n",
              "\n",
              "   first_sentence_similarity  answer_length_tokens  answer_length_chars  \\\n",
              "0                   0.125558                 429.0               2010.0   \n",
              "1                   0.325216                 429.0               2010.0   \n",
              "2                   0.745094                 263.0               1246.0   \n",
              "3                   0.214009                 263.0               1246.0   \n",
              "4                   0.123043                 525.0               2502.0   \n",
              "\n",
              "   answer_to_question_len_ratio  num_sentences  hedge_score  ...  \\\n",
              "0                     17.033898           21.0         21.0  ...   \n",
              "1                     17.631579           21.0         21.0  ...   \n",
              "2                      7.506024           19.0         10.0  ...   \n",
              "3                      8.964029           19.0         10.0  ...   \n",
              "4                     30.144578           33.0         14.0  ...   \n",
              "\n",
              "   pos_ratio_verbs  pos_ratio_nouns  pos_ratio_pronouns  num_clauses  \\\n",
              "0         0.142857         0.131868            0.093407         40.0   \n",
              "1         0.142857         0.131868            0.093407         40.0   \n",
              "2         0.162162         0.139640            0.099099         21.0   \n",
              "3         0.162162         0.139640            0.099099         21.0   \n",
              "4         0.139640         0.164414            0.101351         26.0   \n",
              "\n",
              "   starts_with_thanks  pivot_score  negation_count  deflection_score  \\\n",
              "0                 0.0          0.0             4.0             0.875   \n",
              "1                 0.0          0.0             4.0             0.875   \n",
              "2                 0.0          0.0             8.0             0.500   \n",
              "3                 0.0          0.0             8.0             1.000   \n",
              "4                 0.0          0.0             6.0             1.000   \n",
              "\n",
              "        ttr  entropy_score  \n",
              "0  0.465714       6.722073  \n",
              "1  0.465714       6.722073  \n",
              "2  0.528302       6.303390  \n",
              "3  0.528302       6.303390  \n",
              "4  0.497685       7.100189  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================\n",
        "# VIEW EXTRACTED FEATURES\n",
        "# ============================================\n",
        "\n",
        "# List all new feature columns\n",
        "feature_columns = [\n",
        "    # Semantic\n",
        "    'qa_similarity', 'topic_shift_score', 'keyword_overlap', 'entity_overlap', 'first_sentence_similarity',\n",
        "    # Structure\n",
        "    'answer_length_tokens', 'answer_length_chars', 'answer_to_question_len_ratio', 'num_sentences',\n",
        "    # Hedging\n",
        "    'hedge_score', 'filler_score', 'vague_word_count', 'modal_verb_count',\n",
        "    # Specificity\n",
        "    'num_numbers', 'num_named_entities', 'specificity_score', 'concreteness_score',\n",
        "    # Sentiment\n",
        "    'sentiment_compound', 'sentiment_positive', 'sentiment_negative', 'sentiment_neutral', 'emotion_confidence',\n",
        "    # Syntactic\n",
        "    'pos_ratio_verbs', 'pos_ratio_nouns', 'pos_ratio_pronouns', 'num_clauses',\n",
        "    # Evasion\n",
        "    'starts_with_thanks', 'pivot_score', 'negation_count', 'deflection_score',\n",
        "    # Lexical diversity\n",
        "    'ttr', 'entropy_score'\n",
        "]\n",
        "\n",
        "print(f\"Total feature columns: {len(feature_columns)}\\n\")\n",
        "print(\"Feature columns:\")\n",
        "for i, col in enumerate(feature_columns, 1):\n",
        "    print(f\"  {i:2d}. {col}\")\n",
        "\n",
        "# Show sample of features\n",
        "train_df[feature_columns].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "588b70dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature statistics by label:\n",
            "\n",
            "label                         Claims ignorance  Clarification  \\\n",
            "qa_similarity                            0.327          0.179   \n",
            "topic_shift_score                        0.673          0.821   \n",
            "keyword_overlap                          0.237          0.054   \n",
            "entity_overlap                           0.218          0.065   \n",
            "first_sentence_similarity                0.234          0.160   \n",
            "answer_length_tokens                   199.924        105.620   \n",
            "answer_length_chars                    902.269        496.076   \n",
            "answer_to_question_len_ratio            16.063          7.612   \n",
            "num_sentences                           12.403          5.511   \n",
            "hedge_score                              8.613          4.413   \n",
            "filler_score                             2.597          1.217   \n",
            "vague_word_count                         2.513          1.326   \n",
            "modal_verb_count                         2.899          0.989   \n",
            "num_numbers                              1.361          1.011   \n",
            "num_named_entities                       6.899          3.293   \n",
            "specificity_score                        0.345          0.277   \n",
            "concreteness_score                       0.237          0.238   \n",
            "sentiment_compound                       0.543          0.162   \n",
            "sentiment_positive                       0.130          0.091   \n",
            "sentiment_negative                       0.041          0.043   \n",
            "sentiment_neutral                        0.829          0.866   \n",
            "emotion_confidence                       0.636          0.245   \n",
            "pos_ratio_verbs                          0.173          0.185   \n",
            "pos_ratio_nouns                          0.108          0.095   \n",
            "pos_ratio_pronouns                       0.175          0.242   \n",
            "num_clauses                             12.403          7.674   \n",
            "starts_with_thanks                       0.008          0.000   \n",
            "pivot_score                              0.025          0.043   \n",
            "negation_count                           4.076          1.772   \n",
            "deflection_score                         0.710          0.353   \n",
            "ttr                                      0.647          0.857   \n",
            "entropy_score                            5.218          3.304   \n",
            "\n",
            "label                         Declining to answer  Deflection   Dodging  \\\n",
            "qa_similarity                               0.248       0.359     0.254   \n",
            "topic_shift_score                           0.752       0.641     0.746   \n",
            "keyword_overlap                             0.125       0.300     0.173   \n",
            "entity_overlap                              0.152       0.409     0.204   \n",
            "first_sentence_similarity                   0.191       0.271     0.191   \n",
            "answer_length_tokens                      180.669     444.412   317.731   \n",
            "answer_length_chars                       839.600    2073.724  1510.436   \n",
            "answer_to_question_len_ratio               11.491      25.545    24.318   \n",
            "num_sentences                              10.179      24.525    16.802   \n",
            "hedge_score                                 7.683      18.013    13.258   \n",
            "filler_score                                2.186       5.021     3.261   \n",
            "vague_word_count                            2.510       6.310     4.203   \n",
            "modal_verb_count                            2.386       5.596     4.025   \n",
            "num_numbers                                 1.421       4.037     2.592   \n",
            "num_named_entities                          6.317      16.365    11.564   \n",
            "specificity_score                           0.388       0.376     0.399   \n",
            "concreteness_score                          0.251       0.270     0.302   \n",
            "sentiment_compound                          0.383       0.629     0.516   \n",
            "sentiment_positive                          0.127       0.136     0.165   \n",
            "sentiment_negative                          0.042       0.054     0.056   \n",
            "sentiment_neutral                           0.831       0.810     0.779   \n",
            "emotion_confidence                          0.553       0.835     0.695   \n",
            "pos_ratio_verbs                             0.187       0.151     0.149   \n",
            "pos_ratio_nouns                             0.131       0.146     0.124   \n",
            "pos_ratio_pronouns                          0.164       0.128     0.136   \n",
            "num_clauses                                12.324      29.331    21.273   \n",
            "starts_with_thanks                          0.014       0.005     0.014   \n",
            "pivot_score                                 0.014       0.042     0.024   \n",
            "negation_count                              2.821       6.199     4.484   \n",
            "deflection_score                            0.711       0.904     0.777   \n",
            "ttr                                         0.731       0.517     0.638   \n",
            "entropy_score                               4.932       6.360     5.303   \n",
            "\n",
            "label                         Explicit   General  Implicit  \\\n",
            "qa_similarity                    0.373     0.354     0.367   \n",
            "topic_shift_score                0.627     0.646     0.633   \n",
            "keyword_overlap                  0.337     0.312     0.334   \n",
            "entity_overlap                   0.345     0.412     0.443   \n",
            "first_sentence_similarity        0.275     0.250     0.260   \n",
            "answer_length_tokens           328.386   402.987   467.863   \n",
            "answer_length_chars           1541.026  1900.427  2227.006   \n",
            "answer_to_question_len_ratio    23.851    26.225    29.260   \n",
            "num_sentences                   17.943    20.661    23.549   \n",
            "hedge_score                     13.321    16.977    19.139   \n",
            "filler_score                     3.639     4.256     4.986   \n",
            "vague_word_count                 4.389     5.464     6.143   \n",
            "modal_verb_count                 4.075     5.484     6.002   \n",
            "num_numbers                      2.939     3.181     3.920   \n",
            "num_named_entities              11.994    14.852    17.609   \n",
            "specificity_score                0.400     0.391     0.384   \n",
            "concreteness_score               0.264     0.250     0.258   \n",
            "sentiment_compound               0.531     0.637     0.613   \n",
            "sentiment_positive               0.175     0.142     0.132   \n",
            "sentiment_negative               0.066     0.052     0.057   \n",
            "sentiment_neutral                0.759     0.806     0.811   \n",
            "emotion_confidence               0.738     0.791     0.821   \n",
            "pos_ratio_verbs                  0.145     0.151     0.149   \n",
            "pos_ratio_nouns                  0.127     0.136     0.147   \n",
            "pos_ratio_pronouns               0.130     0.125     0.126   \n",
            "num_clauses                     21.958    26.803    31.336   \n",
            "starts_with_thanks               0.004     0.005     0.010   \n",
            "pivot_score                      0.027     0.039     0.064   \n",
            "negation_count                   4.606     5.176     6.404   \n",
            "deflection_score                 0.780     0.856     0.890   \n",
            "ttr                              0.596     0.558     0.527   \n",
            "entropy_score                    5.540     6.051     6.299   \n",
            "\n",
            "label                         Partial/half-answer  \n",
            "qa_similarity                               0.379  \n",
            "topic_shift_score                           0.621  \n",
            "keyword_overlap                             0.282  \n",
            "entity_overlap                              0.519  \n",
            "first_sentence_similarity                   0.256  \n",
            "answer_length_tokens                      429.557  \n",
            "answer_length_chars                      2034.278  \n",
            "answer_to_question_len_ratio               19.934  \n",
            "num_sentences                              22.848  \n",
            "hedge_score                                17.038  \n",
            "filler_score                                4.468  \n",
            "vague_word_count                            5.848  \n",
            "modal_verb_count                            4.810  \n",
            "num_numbers                                 3.582  \n",
            "num_named_entities                         16.266  \n",
            "specificity_score                           0.388  \n",
            "concreteness_score                          0.278  \n",
            "sentiment_compound                          0.715  \n",
            "sentiment_positive                          0.147  \n",
            "sentiment_negative                          0.055  \n",
            "sentiment_neutral                           0.798  \n",
            "emotion_confidence                          0.811  \n",
            "pos_ratio_verbs                             0.146  \n",
            "pos_ratio_nouns                             0.138  \n",
            "pos_ratio_pronouns                          0.126  \n",
            "num_clauses                                27.089  \n",
            "starts_with_thanks                          0.013  \n",
            "pivot_score                                 0.063  \n",
            "negation_count                              4.684  \n",
            "deflection_score                            0.868  \n",
            "ttr                                         0.555  \n",
            "entropy_score                               6.063  \n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# ANALYZE FEATURES BY LABEL\n",
        "# ============================================\n",
        "\n",
        "print(\"Feature statistics by label:\\n\")\n",
        "print(train_df.groupby('label')[feature_columns].mean().T.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "686d4920",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved feature-enriched dataset!\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# SAVE ENRICHED DATASET (OPTIONAL)\n",
        "# ============================================\n",
        "\n",
        "# Uncomment to save the feature-enriched dataset\n",
        "train_df.to_parquet('dataset/train_with_features.parquet', index=False)\n",
        "train_df.to_csv('dataset/train_with_features.csv', index=False)\n",
        "print(\"Saved feature-enriched dataset!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
